<h1> Emergence of linguistic communication from referential games with symbolic
and pixel input </h1>

## A. Lazaridou, K. M. Hermann, K. Tuyls, S. Clark



---



## Abstract



---



## I - Introduction

* Study of emergent communication :
  * **language evolution** - development of communication protocols from scratch
  * **language acquisition** - learning of an existing language

<br>

* Focus on **how environmental or pre-linguistic conditions affect the nature
of the communication protocol that an agent learns.** Increasing realism and
complexity.

* Intuition that language derives meaning from its use.

* Context of a **simple referential game**, where one agent must communicate to
another a target object in the agent's environment.

<br>

* **Compositionality** : smaller building blocks are used to generate
unbounded numbers of more complex forms, with the meaning of the larger being
determined by the meanings of its parts and how they are put together
(allows virtually infinite expression)

* In this paper:
  * Two referential communication games to study **how much structure is
  provided by the environment** (same setup, learning procedure, architecture)
  * Study 1 - symbolic input, disentangled representations, dimensions encode
  individual properties
  * Study 2 - raw perceptual input, entangled input, no pro-coded semantics
  * **Learning agents can successfully communicate in both cases, but struggle
  to produce structured messages when presented with entangled input data.**



---



## II - Referential games as multi-agent co-operative reinforcement learning

* General framework in which two agents take discrete actions in their
environment in order to **maximize a shared reward.**


<br>


### II.1 - Game and terminology

* A **speaker** is presented with a **target object $t$** (among the set of
  **pre-linguistic items**, e.g. pixel-based images). Using an **alphabet**
(primitive discrete **symbols**, e.g. ('22','10','0', '2')), the speaker
constructs a **message** describing that object (e.g. '22 0 2').

* The set of all distinct messages generated by the speaker is referred to as
their **lexicon** or **protocol**.

* The **listener** is presented with the target and a set of **distractor
objects** $C$ (also among the pre-linguistic set), and - by making use of the
message - has to identify the true target object.

* **Communicative success** is the correct identification of the target
by the listener.

<br>

<center>

![Referential game](pictures/05-referential_game.png)

**Referential game setting: the listener tries to guess the target object among
a set of candidate objects, by making use of the speaker's message.**

</center>

<br>


### II.2 - Agents

* The speaker :
  * **Encodes $t$** into a dense representation $u$ using an encoder (depends
    on the pre-linguistic set)
  * **Generates a message $m$** based on $u$ and the alphabet (symbols of the
    alphabet have no a priori meaning), using a **decoder** (here single-layer
    LSTM).

<br>

* The listener :
  * **Encodes all candidates $c$** using an encoder (similar to, but
    independent of the speaker's encoder)
  * **Encodes the message $m$** using an encoder (here a single-layer LSTM)
    to produce an **encoding $z$.**
  * **Predicts a target object $t' \in C$** based on $z \cdot u_c$  


<br>


### II-3. Learning

* All weights of the speaker and listener (encoders, decoders) are jointly
optimized.

* **No weights are shared between both agents, the only supervision is
communicative success.**

<br>

<center>

![Reward function](pictures/05-reward.png)

**Reward function, with $R(t') = \mathbb{1}_{\{t=t'\}}$**

</center>

<br>



---



## III - Study 1: Referential game with symbolic data

* **Structured and disentangled input** (bag-of-attributes, all pre-linguistic
  items are represented in terms of binary vectors $o \in \{0,1\}^{573}$).
  Each object can be seen as a conjonction of properties.

* Speaker and listener convert the pre-linguistic representations to dense
representations $u$ by using a single-layer MLP.

* 4 distractors, alphabet of 100 symbols.


<br>


### III.1 - Agent performance and ambiguity

<br>

<center>

![Study1 results](pictures/05-study1_results.png)

**Results of Study 1. <br> `alphabet size` denotes the effective size of the
symbol set used, `lexicon size` the effective number of unique messages used,
`topographic $\rho$` the structural similarity in terms of Spearman correlation
between the message and the object vector space.**

</center>

<br>

* In the shortest message setting, we observe a **high ambiguity**, each message
being used to denote 11 concepts on average. Hypothesis : difficult
exploration + ambiguous protocols are good local optima.

* This situation is termed **partial equilibrium pooling**, and can be countered
by increasing the search space (increasing allowed message length).


<br>


### III.2 - Realistic context distribution

* In the real world, distractors are not drawn from a uniform distribution
(context and co-occurence). An additional experiment is designed with
**distractors sampled from a target-specific distribution.**

<br>

<center>

![Study1 context](pictures/05-study1_context.png)

</center>

<br>

* The context-dependent setting initially makes the problem easier,
but similar objects are more likely to appear together as candidates,
and the overall game becomes more difficult.

* **Confusability** : some objects getting mapped to the same message
  * In the uniform case, object similarity is a predictor of object
  confusability
  * In the context-dependent case, object confusability is rather driven by
  co-occurence (to better distinguish co-occurring objects)

<br>

* Thus **the choice of distractors has an effect on the organization (and
potentially the naturalness) of the emerged language**, for example as
reflected in the semantics of ambiguous or homonym words in the language.


<br>


### III.3 - Structural properties of emerged protocols

* **No consensual metric to quantify the degree of compositionality**;
here, the choice taken is to measure the **ability to generalize to novel
data.**

<br>

#### III.3.1 - Generalization to novel objects

* Three sets of unseen object, by decreasing degree of resemblance with the
training data :
  * **test** - same data distribution as training data (but never seen)
  * **unigram chimeras** - property-based distribution inferred from the
  training data
  * **uniform chimeras** - uniformly sampling properties

<br>

<center>

![Generalization](pictures/05-generalization.png)

</center>

<br>

* **Productivity** - speakers are able to concoct novel messages on-the-fly
(see `lexicon_size` for the percentage of novel messages), and listeners to
comprehend them.

<br>

#### III.3.2 - Topographic similarity

<br>

<center>

![Generalization](pictures/05-topographic_similarity.png)

</center>

<br>

* **Topographic similarity is the correlation of the distances between all
possible pairs of meanings and the corresponding pairs of signals.**

* Regarding the formula, topographic similarity is the negative Spearman
correlation between Levensthein distance and cosine similarity.

* Intuitively, it measures the point to which similar (resp. dissimilar)
objects share much (resp. little) of the message structure (e.g. prefixes).

* Results suggest that structured and disentangled pre-linguistic
representations are a sufficient condition for the emergence of structured
languages (in addition, neural agents tend to favor similar inputs to
trigger similar outputs).
